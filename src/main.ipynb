{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T13:53:40.056060Z",
     "start_time": "2025-11-03T13:48:24.259166Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mamy0\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [08:30<00:00, 156.66it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [08:22<00:00, 159.11it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16000/16000 [01:31<00:00, 174.25it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16000/16000 [01:32<00:00, 173.35it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [13:08<00:00, 101.40it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80000/80000 [13:09<00:00, 101.34it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16000/16000 [02:03<00:00, 129.08it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16000/16000 [02:06<00:00, 126.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "train_dataset = load_dataset(\"swan07/authorship-verification\", split=\"train[:80000]\")\n",
    "test_dataset = load_dataset(\"swan07/authorship-verification\", split=\"test[:16000]\")\n",
    "\n",
    "from specter import SpecterVectorizer\n",
    "\n",
    "spectorVectorizer = SpecterVectorizer()\n",
    "spectorVectorizer.load()\n",
    "\n",
    "train_spector = spectorVectorizer.embed(train_dataset)\n",
    "test_spector = spectorVectorizer.embed(test_dataset)\n",
    "\n",
    "from bert import BertVectorizer\n",
    "\n",
    "bertVectorizer = BertVectorizer()\n",
    "bertVectorizer.load()\n",
    "\n",
    "train_bert = bertVectorizer.embed(train_dataset)\n",
    "test_bert = bertVectorizer.embed(test_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916b4206e44ee798",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ï†ÄÏû• Ï§ë...\n",
      "‚úì train_specter.pkl\n",
      "‚úì test_specter.pkl\n",
      "‚úì train_bert.pkl\n",
      "‚úì test_bert.pkl\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "Path(\"./embeddings\").mkdir(exist_ok=True)\n",
    "\n",
    "# Ï†ÄÏû•\n",
    "print(\"Ï†ÄÏû• Ï§ë...\")\n",
    "with open('./embeddings/train_specter.pkl', 'wb') as f:\n",
    "    pickle.dump(train_spector, f)\n",
    "print(\"‚úì train_specter.pkl\")\n",
    "\n",
    "with open('./embeddings/test_specter.pkl', 'wb') as f:\n",
    "    pickle.dump(test_spector, f)\n",
    "print(\"‚úì test_specter.pkl\")\n",
    "\n",
    "with open('./embeddings/train_bert.pkl', 'wb') as f:\n",
    "    pickle.dump(train_bert, f)\n",
    "print(\"‚úì train_bert.pkl\")\n",
    "\n",
    "with open('./embeddings/test_bert.pkl', 'wb') as f:\n",
    "    pickle.dump(test_bert, f)\n",
    "print(\"‚úì test_bert.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c0ac9c7170173865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T18:10:14.726436Z",
     "start_time": "2025-12-09T18:10:11.871393Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "with open('./embeddings/train_bert.pkl', 'rb') as f:\n",
    "    bert_train_data = pickle.load(f)\n",
    "with open('./embeddings/test_bert.pkl', 'rb') as f:\n",
    "    bert_test_data = pickle.load(f)\n",
    "\n",
    "with open('./embeddings/train_bert.pkl', 'rb') as f:\n",
    "    spector_train_data = pickle.load(f)\n",
    "with open('./embeddings/test_bert.pkl', 'rb') as f:\n",
    "    spector_test_data = pickle.load(f)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ea1cced09fb7b5f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T18:20:31.679574Z",
     "start_time": "2025-12-09T18:10:14.917313Z"
    }
   },
   "source": [
    "from classifier import train_authorship_classifiers\n",
    "models, results_bert = train_authorship_classifiers(bert_train_data, bert_test_data, True)\n",
    "models, results_spector = train_authorship_classifiers(spector_train_data, spector_test_data, True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "Preparing features on GPU‚Ä¶\n",
      "=== Training LightGBM (GPU) ===\n",
      "[LightGBM] [Info] Number of positive: 45491, number of negative: 34509\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 979455\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 3841\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 3841 dense feature groups (293.27 MB) transferred to GPU in 0.102038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.568638 -> initscore=0.276294\n",
      "[LightGBM] [Info] Start training from score 0.276294\n",
      "=== Training XGBoost (GPU) ===\n",
      "=== Training CatBoost (GPU) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 8133 Total: 12287.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Neural Network (GPU) ===\n",
      "Epoch 1/10 - Loss 0.4867 - TestAcc 0.7271\n",
      "Epoch 2/10 - Loss 0.4349 - TestAcc 0.7348\n",
      "Epoch 3/10 - Loss 0.4143 - TestAcc 0.7378\n",
      "Epoch 4/10 - Loss 0.3910 - TestAcc 0.7409\n",
      "Epoch 5/10 - Loss 0.3699 - TestAcc 0.7449\n",
      "Epoch 6/10 - Loss 0.3504 - TestAcc 0.7450\n",
      "Epoch 7/10 - Loss 0.3275 - TestAcc 0.7426\n",
      "Epoch 8/10 - Loss 0.3093 - TestAcc 0.7452\n",
      "Epoch 9/10 - Loss 0.2858 - TestAcc 0.7411\n",
      "Epoch 10/10 - Loss 0.2682 - TestAcc 0.7405\n",
      "Using Device: cuda\n",
      "Preparing features on GPU‚Ä¶\n",
      "=== Training LightGBM (GPU) ===\n",
      "[LightGBM] [Info] Number of positive: 45491, number of negative: 34509\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 979455\n",
      "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 3841\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 3841 dense feature groups (293.27 MB) transferred to GPU in 0.106825 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.568638 -> initscore=0.276294\n",
      "[LightGBM] [Info] Start training from score 0.276294\n",
      "=== Training XGBoost (GPU) ===\n",
      "=== Training CatBoost (GPU) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: less than 75% GPU memory available for training. Free: 7793 Total: 12287.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Neural Network (GPU) ===\n",
      "Epoch 1/10 - Loss 0.4859 - TestAcc 0.7243\n",
      "Epoch 2/10 - Loss 0.4345 - TestAcc 0.7331\n",
      "Epoch 3/10 - Loss 0.4144 - TestAcc 0.7378\n",
      "Epoch 4/10 - Loss 0.3918 - TestAcc 0.7401\n",
      "Epoch 5/10 - Loss 0.3710 - TestAcc 0.7452\n",
      "Epoch 6/10 - Loss 0.3489 - TestAcc 0.7370\n",
      "Epoch 7/10 - Loss 0.3280 - TestAcc 0.7396\n",
      "Epoch 8/10 - Loss 0.3080 - TestAcc 0.7360\n",
      "Epoch 9/10 - Loss 0.2917 - TestAcc 0.7426\n",
      "Epoch 10/10 - Loss 0.2681 - TestAcc 0.7392\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T18:26:23.252805Z",
     "start_time": "2025-12-09T18:26:23.248554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MajorityVotingEnsemble:\n",
    "    def __init__(self, model_names):\n",
    "        self.model_names = model_names  # Ïòà: ['pytorch_nn', 'xgboost', 'catboost']\n",
    "\n",
    "    def predict(self, df_pred):\n",
    "        pred_cols = [f\"pred_{m}\" for m in self.model_names]\n",
    "        return df_pred[pred_cols].mode(axis=1)[0]\n",
    "\n",
    "    def compute_disagreement_rate(self, df_pred):\n",
    "        pred_cols = [f\"pred_{m}\" for m in self.model_names]\n",
    "        preds = df_pred[pred_cols].values\n",
    "\n",
    "        disagreement_rates = []\n",
    "        for row in preds:\n",
    "            values, counts = np.unique(row, return_counts=True)\n",
    "            max_count = counts.max()\n",
    "            total = len(row)\n",
    "            disagreement = 1 - (max_count / total)\n",
    "            disagreement_rates.append(disagreement)\n",
    "\n",
    "        return np.mean(disagreement_rates)\n",
    "\n",
    "    def evaluate(self, df_pred, true_label_col=\"true_label\"):\n",
    "        y_true = df_pred[true_label_col]\n",
    "        y_pred = self.predict(df_pred)\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        disagreement_rate = self.compute_disagreement_rate(df_pred)\n",
    "\n",
    "        print(\"\\n==============================\")\n",
    "        print(\"üîÆ Majority Voting Ensemble Í≤∞Í≥º\")\n",
    "        print(\"==============================\")\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Disagreement Rate: {disagreement_rate:.4f}\")\n",
    "        print(\"==============================\\n\")\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": acc,\n",
    "            \"f1\": f1,\n",
    "            \"disagreement_rate\": disagreement_rate\n",
    "        }"
   ],
   "id": "f36047f0df436b3e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "83fad2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T18:26:25.006220Z",
     "start_time": "2025-12-09T18:26:23.374385Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "majority_voting = MajorityVotingEnsemble(models.keys())\n",
    "df_pred = pd.DataFrame({\n",
    "    \"true_label\": bert_test_data[\"same\"],  # Ï†ïÎãµ Î†àÏù¥Î∏î\n",
    "    \"pred_lightgbm\": results_bert.iloc[0][\"pred_test\"],\n",
    "    \"pred_xgboost\": results_bert.iloc[1][\"pred_test\"],\n",
    "    \"pred_catboost\": results_bert.iloc[2][\"pred_test\"],\n",
    "    \"pred_simple_nn\": results_bert.iloc[3][\"pred_test\"],\n",
    "})\n",
    "majority_voting.evaluate(df_pred)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üîÆ Majority Voting Ensemble Í≤∞Í≥º\n",
      "==============================\n",
      "Accuracy: 0.7348\n",
      "F1 Score: 0.7260\n",
      "Disagreement Rate: 0.0849\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7348125,\n",
       " 'f1': 0.7259575017761416,\n",
       " 'disagreement_rate': np.float64(0.084890625)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "6f26b017731db3c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T18:26:26.542546Z",
     "start_time": "2025-12-09T18:26:25.137189Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "majority_voting = MajorityVotingEnsemble(models.keys())\n",
    "df_pred = pd.DataFrame({\n",
    "    \"true_label\": spector_test_data[\"same\"],  # Ï†ïÎãµ Î†àÏù¥Î∏î\n",
    "    \"pred_lightgbm\": results_spector.iloc[0][\"pred_test\"],\n",
    "    \"pred_xgboost\": results_spector.iloc[1][\"pred_test\"],\n",
    "    \"pred_catboost\": results_spector.iloc[2][\"pred_test\"],\n",
    "    \"pred_simple_nn\": results_spector.iloc[3][\"pred_test\"],\n",
    "})\n",
    "majority_voting.evaluate(df_pred)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üîÆ Majority Voting Ensemble Í≤∞Í≥º\n",
      "==============================\n",
      "Accuracy: 0.7352\n",
      "F1 Score: 0.7276\n",
      "Disagreement Rate: 0.0885\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7351875,\n",
       " 'f1': 0.7276467185189947,\n",
       " 'disagreement_rate': np.float64(0.08846875)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T18:31:30.315637Z",
     "start_time": "2025-12-09T18:31:28.860649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "majority_voting = MajorityVotingEnsemble([\"simple_nn_spector\", \"simple_nn_bert\"])\n",
    "df_pred = pd.DataFrame({\n",
    "    \"true_label\": spector_test_data[\"same\"],  # Ï†ïÎãµ Î†àÏù¥Î∏î\n",
    "    \"pred_simple_nn_spector\": results_spector.iloc[3][\"pred_test\"],\n",
    "    \"pred_simple_nn_bert\": results_bert.iloc[3][\"pred_test\"],\n",
    "})\n",
    "majority_voting.evaluate(df_pred)"
   ],
   "id": "d4bc2dee3703d6a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "üîÆ Majority Voting Ensemble Í≤∞Í≥º\n",
      "==============================\n",
      "Accuracy: 0.7400\n",
      "F1 Score: 0.7233\n",
      "Disagreement Rate: 0.0705\n",
      "==============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.74,\n",
       " 'f1': 0.7232570516232039,\n",
       " 'disagreement_rate': np.float64(0.07053125)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fb7e742f4fcbc1cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
